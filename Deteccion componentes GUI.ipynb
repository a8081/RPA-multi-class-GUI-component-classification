{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[LIMPIOv2]Deteccion componentes GUI.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wwC8xE4Dqr2J"},"source":["# Detección de componentes GUI"]},{"cell_type":"markdown","metadata":{"id":"i-c25l3vq0sm"},"source":["El objetivo de esta parte de nuestro trabajo es poder detectar, delimitar y posteriormente recortar, cada uno de los componentes gráficos (símbolos, imágenes o cuadros de texto) que componen una captura de pantalla."]},{"cell_type":"markdown","metadata":{"id":"RkzRzzAcvmYu"},"source":["## Importación de Librerías"]},{"cell_type":"markdown","metadata":{"id":"wnj-BGgVrYdr"},"source":["Nos vamos a servir principalmente de dos librerías, keras_ocr y Opencv (Cv2)."]},{"cell_type":"code","metadata":{"id":"j53MPNM2JrjC"},"source":["pip install keras-ocr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9eRPE1RJxAU","executionInfo":{"status":"ok","timestamp":1613948770384,"user_tz":-60,"elapsed":3789,"user":{"displayName":"José","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggb45GUAo1Sa0_wQfVSl8qBX5Fo6RaGxjEIU2mz=s64","userId":"12229816920471877325"}},"outputId":"91550adf-c878-40e6-c241-95afbc88a7a1"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import keras_ocr\r\n","import cv2\r\n","from google.colab.patches import cv2_imshow\r\n","# keras-ocr will automatically download pretrained\r\n","# weights for the detector and recognizer.\r\n","pipeline = keras_ocr.pipeline.Pipeline()"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Looking for /root/.keras-ocr/craft_mlt_25k.h5\n","Looking for /root/.keras-ocr/crnn_kurapan.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MmLsL0F3ri-9"},"source":["## Detección cuadros de texto: KERAS_OCR"]},{"cell_type":"markdown","metadata":{"id":"bbhH8mOvt8YD"},"source":["Con el objetivo de detectar los cuadros de texto dentro las capturas de pantalla, definimos la función <code>get_keras_ocr_image</code>. Esta función tendrá como input una lista de imagénes, y como output, las coordenadas de las esquinas que conforman cada uno de los cuadros de texto detectados.\r\n"]},{"cell_type":"code","metadata":{"id":"zchJqiHroPGv","executionInfo":{"status":"ok","timestamp":1613957848335,"user_tz":-60,"elapsed":436,"user":{"displayName":"José","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggb45GUAo1Sa0_wQfVSl8qBX5Fo6RaGxjEIU2mz=s64","userId":"12229816920471877325"}}},"source":["image_path = \"/content/Screenshot1.png\""],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ic2R5FAuJ03j","executionInfo":{"status":"ok","timestamp":1613957884181,"user_tz":-60,"elapsed":34469,"user":{"displayName":"José","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggb45GUAo1Sa0_wQfVSl8qBX5Fo6RaGxjEIU2mz=s64","userId":"12229816920471877325"}}},"source":["def get_keras_ocr_image(images_input):\r\n","  \"\"\"\r\n","  Hay que pasarle el path o url de la imagen a tratar, o una lista con las urls en caso de ser varias.\r\n","  \"\"\"\r\n","  if not isinstance(images_input, list):\r\n","    images_input = [images_input]\r\n","  # Get a set of three example images\r\n","  images = [\r\n","      keras_ocr.tools.read(url) for url in images_input\r\n","  ]\r\n","  # Each list of predictions in prediction_groups is a list of\r\n","  # (word, box) tuples.\r\n","  prediction_groups = pipeline.recognize(images)\r\n","  # Plot the predictions\r\n","  # fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\r\n","  # for ax, image, predictions in zip(axs, images, prediction_groups):\r\n","  #     keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)\r\n","  return prediction_groups\r\n","\r\n","imgs = [\r\n","  image_path\r\n","]\r\n","\r\n","esquinas_texto = get_keras_ocr_image(imgs)"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DIVr7MDEvlA3"},"source":["## Detección de bordes y recortes: OpenCV\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"7QeiXF3tw7f9"},"source":["Hacemos uso de la libería OpenCV para llevar a cabo las siguientes tareas:\r\n","- Lectura de la imagen.\r\n","- Cálculo de intervalos ocupados por los cuadros de texto obtenidos a través de keras_ocr\r\n","- Tratamiento de la imagen:\r\n","  > Conversión a escala de grises.\r\n","\r\n","  > Suavizado gaussiano a la imagen.\r\n","\r\n","  > **Algoritmo de Canny** para la detección de bordes.\r\n","\r\n","  > Obtención de contornos.\r\n","\r\n","- Comparación entre contornos y cuadros de texto.\r\n","\r\n","- Recorte final del componente.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Nqta1Wf_DH-BgBN7-jBi3E635wxvdq_X"},"id":"t9yK_4cmwJGU","executionInfo":{"status":"ok","timestamp":1613956908579,"user_tz":-60,"elapsed":5737,"user":{"displayName":"José","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggb45GUAo1Sa0_wQfVSl8qBX5Fo6RaGxjEIU2mz=s64","userId":"12229816920471877325"}},"outputId":"aaec8b8c-c477-42b4-9b01-dfbde7234a97"},"source":["#Leemos la imagen\r\n","\r\n","img = cv2.imread(image_path)\r\n","img_copy = img.copy()\r\n","cv2_imshow(img_copy)\r\n","\r\n","#almaceno en global_y todas las coordenadas y de los cuadros de texto\r\n","#cada fila es un cuadro de texto distinto, mucho más amigable que el formato que devuelve keras_ocr\r\n","global_y = []\r\n","global_x = []\r\n","for j in range(0, len(esquinas_texto[0])):\r\n","  coordenada_y = []\r\n","  coordenada_x = []\r\n","  for i in range(0,len(esquinas_texto[0][j][1])):\r\n","    coordenada_y.append(esquinas_texto[0][j][1][i][1])\r\n","    coordenada_x.append(esquinas_texto[0][j][1][i][0])\r\n","  global_y.append(coordenada_y)\r\n","  global_x.append(coordenada_x)\r\n","  #print('Coord y, cuadro texto ' +str(j+1)+ str(global_y[j]))\r\n","  #print('Coord x, cuadro texto ' +str(j+1)+ str(global_x[j]))\r\n","\r\n","print(\"\\n Numero cuadros de texto detectados \" + str(len(esquinas_texto[0])))\r\n","\r\n","#Calculo los intervalos de los cuadros de texto\r\n","intervalo_y=[]\r\n","intervalo_x=[]\r\n","for j in range(0, len(global_y)):\r\n","  intervalo_y.append([int(max(global_y[j])), int(min(global_y[j]))])\r\n","  intervalo_x.append([int(max(global_x[j])), int(min(global_x[j]))])\r\n","print(\"intervalo y\", intervalo_y)\r\n","print(\"intervalo x\", intervalo_x)\r\n","  \r\n","# Convertimos a escala de grises\r\n","gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","cv2_imshow(gris)\r\n","\r\n","# Aplicar suavizado Gaussiano\r\n","gauss = cv2.GaussianBlur(gris, (5,5), 0)\r\n","cv2_imshow(gauss)\r\n","\r\n","# Detectamos los bordes con Canny\r\n","canny = cv2.Canny(gauss, 50, 150)\r\n","cv2_imshow(canny)\r\n","\r\n","# Buscamos los contornos\r\n","(contornos,_) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n","print(\"\\n Número de componentes GUI detectados:\", len(contornos), \"\\n\")\r\n","\r\n","#y los dibujamos\r\n","cv2.drawContours(img_copy,contornos,-1,(0,0,255), 2)\r\n","cv2_imshow(img_copy)\r\n","\r\n","#Llevamos a cabo los recortes para cada contorno detectado\r\n","recortes = []\r\n","lista_prueba=[]\r\n","\r\n","for j in range(0,len(contornos)):\r\n","  cont_horizontal = []\r\n","  cont_vertical = []\r\n","  #obtenemos componentes máximas y mínimas (eje x,y) del contorno\r\n","  for i in range(0,len(contornos[j])-1):\r\n","    cont_horizontal.append(contornos[j][i][0][0])\r\n","    cont_vertical.append(contornos[j][i][0][1])\r\n","    x = min(cont_horizontal)\r\n","    w = max(cont_horizontal)\r\n","    y = min(cont_vertical)\r\n","    h = max(cont_vertical)\r\n","  print('Coord x, componente' + str(j+1) + '  ' + str(x) + ' : ' + str(w))\r\n","  print('Coord y, componente' + str(j+1) + '  ' + str(y) + ' : ' + str(h))\r\n","  #comprobamos que los contornos no solapen con cuadros de texto y optamos por recortar los cuadros de texto si solapan.\r\n","  condicion_recorte=True\r\n","  for k in range(0,len(intervalo_y)):\r\n","    solapa_y = 0\r\n","    solapa_x = 0\r\n","    if (min(intervalo_y[k]) <= y <= max(intervalo_y[k])) or (min(intervalo_y[k]) <= h <= max(intervalo_y[k])):\r\n","      solapa_y = 1\r\n","    if (min(intervalo_x[k]) <= x <= max(intervalo_x[k])) or (min(intervalo_x[k]) <= w <= max(intervalo_x[k])):\r\n","      solapa_x = 1\r\n","    if ((solapa_y == 1) and (solapa_x == 1)):\r\n","      if (lista_prueba.count(k) == 0):\r\n","        lista_prueba.append(k)\r\n","      else:\r\n","        condicion_recorte = False\r\n","      x = min(intervalo_x[k])\r\n","      w = max(intervalo_x[k])\r\n","      y = min(intervalo_y[k])\r\n","      h = max(intervalo_y[k])\r\n","      #crop_img = img[min(intervalo_y[k]) : max(intervalo_y[k]), min(intervalo_x[k]) : max(intervalo_x[k])]\r\n","      print(\"Componente \" + str(j+1) + \" solapa con cuadro de texto\")\r\n","\r\n","  #if (solapa_y == 1 and solapa_x == 1):\r\n","    #crop_img = img[min(intervalo_y[k]) : max(intervalo_y[k]), min(intervalo_x[k]) : max(intervalo_x[k])]\r\n","    #print(\"Componente \" + str(j+1) + \" solapa con cuadro de texto\")\r\n","    #recortes.append(crop_img)\r\n","  #else:\r\n","  if (condicion_recorte):\r\n","    crop_img = img[y:h, x:w]\r\n","    recortes.append(crop_img)\r\n","\r\n","aux = np.array(recortes)\r\n","np.save(\"cropped_images5.npy\", aux)\r\n","\r\n","print(\"\\n\")\r\n","\r\n","#Mostramos las imagenes recortada\r\n","for i in range(0,len(recortes)):\r\n","  if recortes[i].any():\r\n","    print(\"Componente nº\",i+1,  cv2_imshow(recortes[i]), \"\\n\")\r\n","  else:\r\n","    print(\"componente vacío\")\r\n"],"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"tu1doXcgSPzq"},"source":["# Bibliografía"]},{"cell_type":"markdown","metadata":{"id":"qOcPca7MSTmf"},"source":["**Tutoriales OpenCV:**\r\n","\r\n","Canny edge detection: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html#canny\r\n","\r\n","Contours in OpenCV: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_table_of_contents_contours/py_table_of_contents_contours.html#table-of-content-contours\r\n","\r\n","**Tutoriales Keras-OCR:**\r\n","https://keras-ocr.readthedocs.io/en/latest/\r\n","\r\n","**Ejemplo de proyecto OpenCV:**\r\n","https://programarfacil.com/blog/vision-artificial/detector-de-bordes-canny-opencv/"]}]}